---
title: 'p8105_hw6_yl4923'
author: "Yujia Li"
date: "12/3/2021"
output: github_document
---

## Problem 0
create my public Github repo and local R with a single .Rmd file that renders to github_document.
create a sub-directory to store the local data files used in the assignment, and use relative paths to access these data files.
```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1 Birthweight
```{r data tidy}
# 1.1 convert numeric to factor; missing data
bwt = read_csv(file = "./data/birthweight.csv",
                        col_types = "dddddddddddddddddddd") 
clean_bwt = 
  bwt %>% 
  janitor::clean_names() %>%
  drop_na() %>% 
  mutate(babysex = as.factor(ifelse(babysex == 1, "Male", "Female")),
         frace = as.factor(frace),
         malform = as.factor(ifelse(malform == 0, "Absent", "Present")),
         mrace = as.factor(mrace)) %>% 
  select(bwt, everything())
```
Now there are `r sum(sapply(clean_bwt, function(x)all(any(is.na(x)))))` columns with missing values in the cleaned birth weight data set.

As we are trying to using regression to understand which factors are associated with `bwt` (child birth weight). With `r ncol(clean_bwt) - 1` available predictors, the multicollinearity should be considered. By using `cor(bwt)`, I've found that `frace`-`mrace`, `ppwt-ppbmi` and `ppwt-blength` are highly correlated (>0.85), and thus I would not include these pairs with each other in the model. Now I will start with a step wise regression process.
```{r step-starter, echo = TRUE, results='hide'}
# 1.2.1 model building
saturated_model = lm(bwt ~ ., data = clean_bwt)
step_regress = 
  step(saturated_model, direction = 'both')
```

```{r}
knitr::kable(broom::tidy(step_regress))
```
The result is shown in the table above with a model having `r length(step_regress$coefficients)` coefficients. Since the range of `bwt` ranges from hundreds to thousands, I would suspect that variables included do not necessarily underlie birth weight. Thus, considering factors that I do not think impact a lot on the birth weight, `fincome`, `mheight`,`ppwt`, `gaweeks` and `smoken` are removed. The final hypothesized model will include: `babysex`, `bhead`,`delwt`, `blength`, `mrace`, and `parity`, which is stored as a funciton: 
```{r my-model }
proposed_model = function(df) {
  return(
    lm(bwt ~ babysex + bhead + blength + mrace + parity + delwt, 
       data = df)
  )
}
```

```{r}
# 1.2.2 proposed model evaluation
clean_bwt %>% 
  add_predictions(proposed_model(.)) %>% 
  add_residuals(proposed_model(.)) %>% 
  ggplot(data = ., aes(x = pred, y = resid)) +
  geom_point(alpha = 0.2, color = "red") +
  labs(
    title = "Prediced values vs residuals in proposed model",
    x = "Predicted values",
    y = "Residual values"
  )
```
Apparently, the proposed model is not perfect. The residuals do not form an ideal pattern across the range of predicted values. There are a few values off the general horizontal band at these predictions, suggesting that these children may be outliers. There are also 2 children predicted to have little to negative weight.

```{r}
# 1.3 comparisons with 2 models by cross-validated prediction error 
# M1--length at birth and gestational age as predictors (main effects only)
length_age_model = function(df) {
  return(
    lm(bwt ~ blength + gaweeks, data = df)
  )
}

# M2--head circumference, length, sex, and all interactions (including the three-way interaction) between these
interactions_model = function(df) {
  return(
    lm(bwt ~ bhead + blength + babysex + 
         bhead*blength + bhead*babysex + blength*babysex +
         bhead*blength*babysex,
       data = df)
  )
}

cv = 
  crossv_mc(clean_bwt, 500) %>% 
  # Train the models on the training data
  mutate(proposed_model = map(train, proposed_model),
         la_model = map(train, length_age_model),
         interact_model = map(train, interactions_model)) %>% 
  # Calculate RMSE from the test data
  mutate(rmse_proposed = map2_dbl(proposed_model, test, ~rmse(model = .x, data = .y)),
         rmse_la = map2_dbl(la_model, test, ~rmse(model = .x, data = .y)),
         rmse_int = map2_dbl(interact_model, test, ~rmse(model = .x, data = .y)))
```
As firstly splitting up the data set into a training and test for cross-validation, each of the models on the training data is applied to create training-test pair. RMSE measures then is calculated to obtain the range of accuracy of each model, which would be shown in the graph below.
```{r}
cv %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(data = ., aes(rmse, fill = model)) + 
  geom_density(alpha = 0.3) +
  labs(
    title = "Distribution of RMSE values in model cross-validation",
    x = "RMSE value from test dataset",
    y = "Density"
  )
```
My proposed model and interaction model do a better job than the length-age one in prediction, given the length-age has the highest RMSE. This makes sense as length-age only considers only 2 variables, length at birth and gestational age to predict birth weight. This suggests a lack of covariates decrease the accuracy of prediction compared to the two models with more variables. 


## Problem 2
```{r}
```
